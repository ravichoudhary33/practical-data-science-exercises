{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction (688 only)\n",
    "In this question, you'll build a basic recommendation system using collaborative filtering to make recommendations on a typical recommendation systems dataset, the MovieLens dataset. The purpose of this question is to become familiar with the internals of recommendation systems: both how they train and how they form recommendations. \n",
    "\n",
    "### Grading \n",
    "Your submission will be scored in the following manner: \n",
    "* process - 10pts\n",
    "* train - 15pts\n",
    "* recommend - 10pts\n",
    "\n",
    "## Collaborative Filtering by Matrix Factorization\n",
    "In collaborative filtering we wish to factorize our ratings matrix into two smaller feature matrices whose product is equal to the original ratings matrix. Specifically, given some partially filled ratings matrix $X\\in \\mathbb{R}^{m\\times n}$, we want to find feature matrices $U \\in \\mathbb{R}^{m\\times k}$ and $V \\in \\mathbb{R}^{n\\times k}$ such that $UV^T = X$. In the case of movie recommendation, each row of $U$ could be features corresponding to a user, and each row of $V$ could be features corresponding to a movie, and so $u_i^Tv_j$ is the predicted rating of user $i$ on movie $j$. This forms the basis of our hypothesis function for collaborative filtering: \n",
    "\n",
    "$$h_\\theta(i,j) = u_i^T v_j$$\n",
    "\n",
    "In general, $X$ is only partially filled (and usually quite sparse), so we can indicate the non-presence of a rating with a 0. Notationally, let $S$ be the set of $(i,j)$ such that $X_{i,j} \\neq 0$, so $S$ is the set of all pairs for which we have a rating. The loss used for collaborative filtering is squared loss:\n",
    "\n",
    "$$\\ell(h_\\theta(i,j),X_{i,j}) = (h_\\theta(i,j) - X_{i,j})^2$$\n",
    "\n",
    "The last ingredient to collaborative filtering is to impose an $l_2$ weight penalty on the parameters, so our total loss is:\n",
    "\n",
    "$$\\sum_{i,j\\in S}\\ell(h_\\theta(i,j),X_{i,j}) + \\lambda_u ||U||_2^2 + \\lambda_v ||V||_2^2$$\n",
    "\n",
    "For this assignment, we'll let $\\lambda_u = \\lambda_v = \\lambda$. \n",
    "\n",
    "## MovieLens rating dataset\n",
    "To start off, let's get the MovieLens dataset. This dataset is actually quite large (24+ million ratings), but we will instead use their smaller subset of 100k ratings. You will have to go fetch this from their website. \n",
    "\n",
    "* You can download the archive containing their latest dataset release from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip (last updated October 2016). \n",
    "* For more details (contents and structure of archive), you can read the README at http://files.grouplens.org/datasets/movielens/ml-latest-README.html\n",
    "* You can find general information from their website description located at http://grouplens.org/datasets/movielens/. \n",
    "\n",
    "For this assignment, we will only be looking at the ratings data specifically. However, it is good to note that there is additional data available (i.e. movie data and user made tags for movies) which could be used to improve the ability of the recommendation system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as la\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "# AUTOLAB_IGNORE_START\n",
    "%matplotlib inline\n",
    "# AUTOLAB_IGNORE_STOP\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "movies = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "print len(ratings)\n",
    "ratings.head()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Matrix factorization requires that we have our ratings stored in a matrix of users, so the first task is to take the dataframe and convert it into this format. Note that in general, typically these matrices are extremely large and sparse (especially if you want to process the 24 million ratings), however for the purposes of this assignment a dense representation of this smaller dataset should fit on any machine. \n",
    "\n",
    "### Specification\n",
    "* Split the data by assigning the first $\\mathrm{floor}(9n/10)$ permuted entries to be the training set, and the remaining to be the testing set. Use the order given by the permutation. \n",
    "* Each row of the ratings matrix corresponds to a user. The first row of the matrix should correspond to the first user (by userID), and so on. This is because the set of user IDs already form a consecutive range of numbers. \n",
    "* Each column of the ratings matrix corresponds to a movie. The order of the columns doesn't matter, so long as the resulting list of movie names is accurate. This is because the set of movie IDs does not form a consecutive range of numbers. \n",
    "* Each user and movie that exists in the **ratings** dataframe should be present in the ratings matrix, even if it doesn't have any entries. We will only use the movies dataframe to extract the names of the movies. \n",
    "* Any entry that does not have a rating should have a default value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671L, 9066L) (671L, 9066L) ['Toy Story (1995)', 'Jumanji (1995)', 'Grumpier Old Men (1995)', 'Waiting to Exhale (1995)', 'Father of the Bride Part II (1995)']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def process(ratings, movies, P):\n",
    "    \"\"\" Given a dataframe of ratings and a random permutation, split the data into a training \n",
    "        and a testing set, in matrix form. \n",
    "        \n",
    "        Args: \n",
    "            ratings (dataframe) : dataframe of MovieLens ratings\n",
    "            movies (dataframe) : dataframe of MovieLens movies\n",
    "            P (numpy 1D array) : random permutation vector\n",
    "            \n",
    "        Returns: \n",
    "            (X_tr, X_te, movie_names)  : training and testing splits of the ratings matrix (both \n",
    "                                         numpy 2D arrays), and a python list of movie names \n",
    "                                         corresponding to the columns of the ratings matrices. \n",
    "    \"\"\"\n",
    "    splitpoint = int(math.floor(9.0*len(P)/10))\n",
    "    \n",
    "#     ratings = ratings.merge(movies, on='movieId', how='left')\n",
    "    \n",
    "    users = sorted(set(ratings['userId']))\n",
    "    items = sorted(set(ratings['movieId']))\n",
    "    movies = movies.set_index('movieId')\n",
    "    idMovieDict = movies.loc[:,['title']].to_dict()['title']\n",
    "    \n",
    "    train = ratings.iloc[P[:splitpoint],:]\n",
    "    \n",
    "    test = ratings.iloc[P[splitpoint:],:]\n",
    "    \n",
    "    # given a df make it a full array with zeroes filled in and sorted\n",
    "    def pivotAndArray(df):\n",
    "        pivot = pd.pivot_table(df, values = 'rating', index=['userId'], columns=['movieId'], margins=False)\n",
    "        \n",
    "        pivotdf = pd.DataFrame(pivot).fillna(0)\n",
    "        \n",
    "        # make sure cols exists\n",
    "        for item in items:\n",
    "            if item not in pivotdf:\n",
    "                pivotdf[item] = np.zeros(len(pivotdf))\n",
    "        # make sure row exists\n",
    "        for user in users:\n",
    "            if user not in pivotdf.index:\n",
    "                pivotdf.loc[user,:] = np.zeros(len(pivotdf.columns))\n",
    "        # reorder rows and cols and convert to array\n",
    "        pivotdf = pivotdf.loc[users,items]\n",
    "        \n",
    "        Xarr = pivotdf.values\n",
    "        return Xarr\n",
    "        \n",
    "    X_tr = pivotAndArray(train)\n",
    "    X_te = pivotAndArray(test)\n",
    "    movie_names = [idMovieDict[item] for item in items]\n",
    "    \n",
    "    return X_tr, X_te, movie_names\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "# X_tr, X_te, movieNames = process(ratings, movies, np.random.permutation(len(ratings)))\n",
    "X_tr, X_te, movieNames = process(ratings, movies, np.arange(len(ratings)))\n",
    "print X_tr.shape, X_te.shape, movieNames[:5]\n",
    "pd.DataFrame(data={'row':np.nonzero(X_tr)[0], 'col': np.nonzero(X_tr)[1]}).to_csv('X_tr_test.csv', sep=',')\n",
    "pd.DataFrame(data={'row':np.nonzero(X_te)[0], 'col': np.nonzero(X_te)[1]}).to_csv('X_te_test.csv', sep=',')\n",
    "\n",
    "\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, running this on the small MovieLens dataset using a random permutation gives the following result: \n",
    "    \n",
    "    (671L, 9066L) (671L, 9066L) ['Toy Story (1995)', 'Jumanji (1995)', 'Grumpier Old Men (1995)', 'Waiting to Exhale (1995)', 'Father of the Bride Part II (1995)']\n",
    "\n",
    "Your actual titles may vary depending on the random permutation given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Minimization for Collaborative Filtering\n",
    "Now we build the collaborative filtering recommendation system. We will use a method known as alternating least squares. Essentially, we will alternate between optimizing over $U$ and $V$ by holding the other constant. By treating one matrix as a constant, we get exactly a weighted least squares problem, which has a well-known solution. More details can be found in the lecture notes. \n",
    "\n",
    "### Specification\n",
    "* Similar to the softmax regression on MNIST, there is a verbose parameter here that you can use to print your training err and test error. These should decrease (and converge). \n",
    "* You can assume a dense representation of all the inputs. \n",
    "* You may find it useful to have an indicator matrix W where $W_{ij} = 1$ if there is a rating in $X_{ij}$. \n",
    "* You can initialize U,V with random values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def error(X, U, V):\n",
    "    \"\"\" Compute the mean error of the observed ratings in X and their estimated values. \n",
    "        Args: \n",
    "            X (numpy 2D array) : a ratings matrix as specified above\n",
    "            U (numpy 2D array) : a matrix of features for each user\n",
    "            V (numpy 2D array) : a matrix of features for each movie\n",
    "        Returns: \n",
    "            (float) : the mean squared error of the observed ratings with their estimated values\n",
    "        \"\"\"\n",
    "    def binarize(x):\n",
    "        x = float(x)\n",
    "        if x==0.0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "    W = pd.DataFrame(X)\n",
    "    W = np.array(W.applymap(binarize))\n",
    "    h0 = U.dot(V.T)\n",
    "    sqerr = (h0 - X)**2.0\n",
    "    sqerr = np.multiply(sqerr,W)\n",
    "    sqerr = np.array(pd.DataFrame(sqerr))\n",
    "    mse = sqerr.sum().sum()/W.sum().sum()\n",
    "    return mse\n",
    "\n",
    "def train(X, X_te, k, U, V, niters=51, lam=10, verbose=False):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X (numpy 2D array) : the training ratings matrix as specified above\n",
    "            X_te (numpy 2D array) : the testing ratings matrix as specified above\n",
    "            k (int) : the number of features use in the CF model\n",
    "            U (numpy 2D array) : an initial matrix of features for each user\n",
    "            V (numpy 2D array) : an initial matrix of features for each movie\n",
    "            niters (int) : number of iterations to run\n",
    "            lam (float) : regularization parameter\n",
    "            verbose (boolean) : verbosity flag for printing useful messages\n",
    "            \n",
    "        Returns:\n",
    "            (U,V) : A pair of the resulting learned matrix factorization\n",
    "    \"\"\"\n",
    "    k = U.shape[1]\n",
    "    lam = float(lam)\n",
    "    def binarize(x):\n",
    "        x = float(x)\n",
    "        if x==0.0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "    W = pd.DataFrame(X)\n",
    "    W = np.array(W.applymap(binarize))\n",
    "    \n",
    "    if verbose:\n",
    "        print \"Iter \\t|Train Err \\t\\t|Test Err\"\n",
    "        \n",
    "\n",
    "    # Iterate\n",
    "    for i_num in range(niters):\n",
    "        \n",
    "        # update U\n",
    "        for i in range(U.shape[0]):\n",
    "            Wi = W[i]\n",
    "            Wik = np.array([Wi for ki in range(k)]).T\n",
    "                \n",
    "            # zero out V's according to W\n",
    "            Vz = np.multiply(V,Wik)\n",
    "    \n",
    "            # U = np.linalg.solve(np.dot(V, V.T) + lam, np.dot(V, X.T)).T\n",
    "            firstterm = np.dot(Vz.T, Vz) + lam*np.eye(k)\n",
    "            secondterm = np.dot(Vz.T,X[i])\n",
    "            \n",
    "            U[i] = np.linalg.solve(firstterm, secondterm)     \n",
    "            \n",
    "        # update V\n",
    "        for j in range(V.shape[0]):\n",
    "            Wj = W[:,j]\n",
    "            Wjk = np.array([Wj for ki in range(k)]).T\n",
    "            \n",
    "            # zero out U's according to W\n",
    "            Uz = np.multiply(U,Wjk)\n",
    "    \n",
    "            # V = np.linalg.solve(np.dot(U.T, U) + lam, np.dot(U.T, X)).T\n",
    "            firstterm = np.dot(Uz.T, Uz) + lam*np.eye(k)\n",
    "            secondterm = np.dot(Uz.T,X[:,j])\n",
    "            \n",
    "            V[j] = np.linalg.solve(firstterm, secondterm)\n",
    "            \n",
    "\n",
    "\n",
    "        if verbose and (i_num % 5 == 0):\n",
    "            print i_num,\"\\t|\", error(X, U, V),\"\\t|\",error(X_te, U, V)\n",
    "               \n",
    "    return (U,V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671L, 5L)\n",
      "(9066L, 5L)\n",
      "[[  4.17022005e-01   7.20324493e-01   1.14374817e-04   3.02332573e-01\n",
      "    1.46755891e-01]\n",
      " [  9.23385948e-02   1.86260211e-01   3.45560727e-01   3.96767474e-01\n",
      "    5.38816734e-01]\n",
      " [  4.19194514e-01   6.85219500e-01   2.04452250e-01   8.78117436e-01\n",
      "    2.73875932e-02]\n",
      " ..., \n",
      " [  5.63706255e-01   2.38585596e-01   8.39953772e-01   7.65850992e-01\n",
      "    9.65542580e-01]\n",
      " [  5.22988075e-01   1.06524658e-01   9.36617023e-01   8.34235989e-01\n",
      "    5.44418161e-01]\n",
      " [  8.36302277e-01   8.81690919e-01   7.76081137e-01   5.71253977e-01\n",
      "    6.15298721e-01]] [[  4.17022005e-01   7.20324493e-01   1.14374817e-04   3.02332573e-01\n",
      "    1.46755891e-01]\n",
      " [  9.23385948e-02   1.86260211e-01   3.45560727e-01   3.96767474e-01\n",
      "    5.38816734e-01]\n",
      " [  4.19194514e-01   6.85219500e-01   2.04452250e-01   8.78117436e-01\n",
      "    2.73875932e-02]\n",
      " ..., \n",
      " [  1.92629004e-01   6.57614091e-01   5.08837562e-01   9.03958103e-01\n",
      "    1.16927128e-01]\n",
      " [  7.36396130e-01   6.19489508e-01   9.23304960e-01   4.13385183e-02\n",
      "    5.98718257e-01]\n",
      " [  5.08828928e-01   5.07565186e-01   8.68159267e-01   2.38804981e-01\n",
      "    7.17102496e-01]]\n",
      "Iter \t|Train Err \t\t|Test Err\n",
      "0 \t| 0.939258672529 \t| 13.5776674446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.63565493,  0.79565902,  0.69109732,  0.66534732,  0.72820755],\n",
       "        [ 1.03615151,  1.17637103,  1.21817972,  1.38213365,  1.01752477],\n",
       "        [ 0.96551685,  1.15740768,  1.08939301,  1.05916959,  1.34309229],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " array([[ 0.53804873,  0.40113425,  0.25991784,  0.99841317,  0.79865085],\n",
       "        [ 0.18084873,  0.35702198,  0.64210338,  0.98441144,  0.40538391],\n",
       "        [ 0.9523489 ,  0.48202416,  0.35937115,  0.68873364, -0.01008089],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.01783848,  0.68238309,  0.11249726,  0.21670352,  0.10998368]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "k=5\n",
    "np.random.seed(1)\n",
    "U = np.random.rand(X_tr.shape[0],k)\n",
    "\n",
    "np.random.seed(1)\n",
    "V = np.random.rand(X_tr.shape[1],k)\n",
    "print U.shape\n",
    "print V.shape\n",
    "print U, V\n",
    "# error(X_tr, U, V)\n",
    "train(X_tr, X_te, k, U, V, niters=2, lam=10, verbose=True)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "# print V[0].shape\n",
    "# print V[0,:].shape\n",
    "# print V[0,None].T.shape\n",
    "vsum = sum(np.dot(V[j,None].T,V[j,None]) for  j in range(V.shape[0])) + np.eye(5)*10\n",
    "print vsum\n",
    "v1 = pd.DataFrame(V[0])\n",
    "v2 = pd.DataFrame(V[0]).transpose()\n",
    "print v1.shape \n",
    "print v2.shape \n",
    "print v1.dot(v2)\n",
    "\n",
    "vdf = pd.DataFrame(V)\n",
    "\n",
    "np.array([V[0] for k in range(5)]).T\n",
    "sum(V[0]**2)\n",
    "# print vsum\n",
    "# print X_tr[4,0]\n",
    "# np.dot(np.linalg.inv(vsum),V[0]*X_tr[4,0])\n",
    "# np.linalg.solve(vsum, V[0]*X_tr[4,0])\n",
    "# V[1]\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the recommendation system with a random initialization of U,V with 5 features and $\\lambda = 10$ results in the following output. Your results may vary depending on your random permutation.  \n",
    "\n",
    "    Iter |Train Err |Test Err  \n",
    "        0|    1.3854|    2.1635\n",
    "        5|    0.7309|    1.5782\n",
    "       10|    0.7029|    1.5078\n",
    "       15|    0.6951|    1.4874\n",
    "       20|    0.6910|    1.4746\n",
    "       25|    0.6898|    1.4679\n",
    "       30|    0.6894|    1.4648\n",
    "       35|    0.6892|    1.4634\n",
    "       40|    0.6891|    1.4631\n",
    "       45|    0.6891|    1.4633\n",
    "       50|    0.6891|    1.4636\n",
    "    Wall time: 7min 32s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Finally, we need to be able to make recommendations given a matrix factorization. We can do this by simply taking the recommending the movie with the highest value in the estimated ratings matrix. \n",
    "\n",
    "### Specification\n",
    "* For each user, recommend the the movie with the highest predicted rating for that user that the user **hasn't** seen before. \n",
    "* Return the result in a list such that the ith element in this list is the recommendation for the user corresponding to the ith row of the ratings matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "def binarize(x):\n",
    "    x = int(x)\n",
    "    if x==0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n",
    "test = pd.DataFrame(np.array([[1,0,3],[4,0.0,6],[7,0,0]]))\n",
    "test2 = pd.DataFrame(np.array([[7,7,7],[7,7,7],[7,7,7]]))\n",
    "bintest = test.applymap(binarize)\n",
    "print test\n",
    "print bintest\n",
    "print type(test)\n",
    "print type(bintest)\n",
    "print np.multiply(test2,bintest)\n",
    "print sum(np.array([[7,7,7],[7,7,7],[7,7,7]]))\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,0,3],[4,0.0,6],[7,0,0]])\n",
    "a[1,2]\n",
    "b = np.array([1,1,1])\n",
    "np.dot(b,b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend(X, U, V, movieNames):\n",
    "    \"\"\" Recommend a new movie for every user.\n",
    "        Args: \n",
    "            X (numpy 2D array) : the training ratings matrix as specified above\n",
    "            U (numpy 2D array) : a learned matrix of features for each user\n",
    "            V (numpy 2D array) : a learned matrix of features for each movie\n",
    "            movieNames : a list of movie names corresponding to the columns of the ratings matrix\n",
    "        Returns\n",
    "            (list) : a list of movie names recommended for each user\n",
    "    \"\"\"\n",
    "    def binarizeFlipped(x):\n",
    "        x = int(x)\n",
    "        if x==0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    W = pd.DataFrame(X)\n",
    "    W = np.array(W.applymap(binarizeFlipped))\n",
    "    \n",
    "    X_new = np.multiply(U.dot(V.T),W)\n",
    "    X_new= pd.DataFrame(X_new, columns=movieNames)\n",
    "    recs = X_new.idxmax(axis=1)\n",
    "    \n",
    "    return recs.tolist()\n",
    "    \n",
    "# AUTOLAB_IGNORE_START\n",
    "recommendations = recommend(X_tr, U, V, movieNames)\n",
    "# recommendations\n",
    "print recommendations[:10]\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation gets the following results (we can see they are all fairly popular and well known movies that were recommended). Again your results will vary depending on the random permutation. \n",
    "\n",
    "    ['Shawshank Redemption, The (1994)', 'Shawshank Redemption, The (1994)', 'Shawshank Redemption, The (1994)', 'Shawshank Redemption, The (1994)', 'Shawshank Redemption, The (1994)', 'Shawshank Redemption, The (1994)', 'Godfather, The (1972)', 'Fargo (1996)', 'Godfather, The (1972)', \"Schindler's List (1993)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
